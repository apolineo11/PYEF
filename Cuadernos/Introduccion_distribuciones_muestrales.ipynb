{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Introducción a la Inferencia Estadística y Distribuciones Muestrales**\n",
    "\n",
    "## **1. Introducción**\n",
    "La estadística es la disciplina encargada de extraer información de datos y tomar decisiones fundamentadas en ellos. Sin embargo, debido a restricciones de tiempo, recursos y accesibilidad, no siempre es posible analizar la totalidad de la población, lo que nos lleva a trabajar con muestras.\n",
    "\n",
    "### **Población y muestra**\n",
    "- **Población ($\\mathcal{P}$)**: Conjunto total de elementos bajo estudio.\n",
    "- **Muestra ($\\mathcal{M}$)**: Subconjunto extraído de la población.\n",
    "\n",
    "### **Ambivalencia de muestra y población en estadística**\n",
    "El concepto de muestra aleatoria no solo implica la selección de elementos, sino que introduce una dualidad fundamental en estadística: una muestra es un subconjunto de la población, pero al mismo tiempo es una realización de una variable aleatoria. Esto genera una ambivalencia entre muestra y población, dado que la población puede interpretarse como una distribución de probabilidad y la muestra como una observación parcial de esa distribución. Desde una perspectiva epistemológica, la inferencia estadística se fundamenta en la posibilidad de extraer conclusiones generales a partir de observaciones parciales. Dado que cada elemento de la muestra puede considerarse una variable aleatoria, la población misma puede verse como un conjunto de variables latentes que generan los datos observados. Esta perspectiva permite modelar la incertidumbre y la variabilidad inherente a los datos, asegurando que las inferencias sean representativas del proceso subyacente.\n",
    "\n",
    "**Definición:** Una **muestra aleatoria** es una sucesión finita de variables aleatorias $X_1, X_2, \\dots, X_n$ independientes e idénticamente distribuidas (i.i.d.). En el caso de una sucesión infinita de variables aleatorias independientes, se habla de un **proceso estocástico**.\n",
    "\n",
    "**Ejemplo:**\n",
    "Si queremos conocer el ingreso promedio de los habitantes de una ciudad, no es práctico encuestar a todos. En su lugar, tomamos una muestra aleatoria de personas y usamos sus respuestas para estimar el ingreso medio.\n",
    "\n",
    "## **2. Inferencia estadística y modelos probabilísticos**\n",
    "La inferencia estadística se basa en la idea de que podemos usar datos muestrales para obtener información sobre la población. Para esto, se hace uso de modelos probabilísticos que permiten representar la variabilidad de los datos.\n",
    "\n",
    "### **Estimadores y estimaciones**\n",
    "Un **estimador** es una función de la muestra utilizada para aproximar un parámetro desconocido de la población. Un **estimado** o **estimación** es el valor específico que toma el estimador en una muestra particular.\n",
    "\n",
    "**Ejemplo de estadísticos:**\n",
    "- La media muestral $\\bar{X} = \\frac{1}{n} \\sum_{i=1}^{n} X_i$ estima la media poblacional $\\mu$.\n",
    "- La varianza muestral $S^2 = \\frac{1}{n-1} \\sum_{i=1}^{n} (X_i - \\bar{X})^2$ estima la varianza poblacional $\\sigma^2$.\n",
    "- La mediana muestral es un estimador robusto de la tendencia central.\n",
    "- El máximo verosímil es un estimador basado en la optimización de la función de verosimilitud.\n",
    "- La curtosis y la asimetría son estadísticos que describen la forma de la distribución de los datos.\n",
    "\n",
    "## **3. Momentos muestrales**\n",
    "Los momentos muestrales permiten describir la distribución de los datos en la muestra. Son equivalentes a los momentos poblacionales pero calculados a partir de la muestra.\n",
    "\n",
    "Los momentos muestrales de orden $r$ se definen como:\n",
    "\n",
    "$$ M_{r,n} = \\frac{1}{n} \\sum_{i=1}^{n} X_i^r $$\n",
    "\n",
    "Para el caso de los momentos centrales:\n",
    "\n",
    "$$ M_{r,n}^c = \\frac{1}{n} \\sum_{i=1}^{n} (X_i - \\bar{X})^r $$\n",
    "\n",
    "Algunos momentos importantes son:\n",
    "- **Primer momento muestral**: La media muestral $M_{1,n} = \\bar{X}$.\n",
    "- **Segundo momento central muestral**: La varianza muestral $M_{2,n}^c = S^2$.\n",
    "- **Tercer momento central**: Asimetría de la distribución.\n",
    "- **Cuarto momento central**: Curtosis de la distribución.\n",
    "\n",
    "## **4. Reflexión sobre calidad y cantidad de información**\n",
    "En estadística, la calidad y cantidad de información juegan un papel fundamental en la precisión de las inferencias. Un proceso de inferencia sería ideal si contáramos con una gran cantidad de información de excelente calidad. Sin embargo, en la práctica:\n",
    "- Una gran cantidad de datos con baja calidad no produce buenos resultados.\n",
    "- Un pequeño conjunto de datos de alta calidad también puede ser insuficiente.\n",
    "\n",
    "Este equilibrio es representado en la siguiente reflexión:\n",
    "> \"El proceso de inferencia sería inigualable si se contara con toda la información de excelente calidad, circunstancia prácticamente no factible.\"\n",
    "\n",
    "### **Dilemas en la recolección de datos**\n",
    "1. **Costo vs. precisión**: Aumentar la cantidad de datos puede ser costoso sin necesariamente mejorar la inferencia.\n",
    "2. **Representatividad**: Una muestra grande no necesariamente es mejor si tiene sesgos de selección.\n",
    "3. **Ruido en los datos**: Datos en exceso pueden introducir errores si la calidad del muestreo no es rigurosa.\n",
    "\n",
    "**Ejemplo:**\n",
    "Si un investigador recolecta una muestra de opiniones sobre un producto pero solo encuesta a un grupo sesgado, sus estimaciones serán inexactas a pesar de la cantidad de datos.\n",
    "\n",
    "**Preguntas de Reflexión:**\n",
    "1. ¿Por qué es importante trabajar con muestras en lugar de estudiar toda la población?\n",
    "2. ¿Cómo afecta el tamaño de la muestra la precisión de nuestras estimaciones?\n",
    "3. ¿Cuándo un estimador se considera bueno en términos de insesgamiento y eficiencia?\n",
    "4. ¿Cómo podría cambiar nuestra estrategia si la población no sigue una distribución normal?\n",
    "5. ¿Es preferible recolectar muchos datos o mejorar la metodología de muestreo?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Distribuciones Muestrales y Propiedades Estadísticas**\n",
    "\n",
    "## **5. Media Muestral**\n",
    "La media muestral es una de las estadísticas más utilizadas en inferencia estadística. Se define como:\n",
    "\n",
    "$$ \\bar{X} = \\frac{1}{n} \\sum_{i=1}^{n} X_i $$\n",
    "\n",
    "Donde $X_1, X_2, \\dots, X_n$ son variables aleatorias independientes e idénticamente distribuidas (i.i.d.) extraídas de una población con media $\\mu$ y varianza $\\sigma^2$.\n",
    "\n",
    "### **Propiedades de la Media Muestral**\n",
    "1. **Insesgadez:** La media muestral es un estimador insesgado de la media poblacional:\n",
    "\n",
    "   $$ E[\\bar{X}] = \\mu $$\n",
    "\n",
    "2. **Varianza:** La varianza de la media muestral se reduce a medida que el tamaño de la muestra aumenta:\n",
    "\n",
    "   $$ \\text{Var}(\\bar{X}) = \\frac{\\sigma^2}{n} $$\n",
    "\n",
    "3. **Consistencia:** A medida que $n \\to \\infty$, la media muestral converge en probabilidad a la media poblacional.\n",
    "\n",
    "## **6. Teorema Central del Límite (TCL)**\n",
    "El Teorema Central del Límite (TCL) establece que, para una muestra suficientemente grande de una población con media $\\mu$ y varianza finita $\\sigma^2$, la distribución de la media muestral se aproxima a una distribución normal:\n",
    "\n",
    "$$ \\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}} \\sim N(0,1) $$\n",
    "\n",
    "independientemente de la distribución de la población original.\n",
    "\n",
    "### **Ejemplo 1: Aproximación de la distribución binomial**\n",
    "Si $X_i \\sim \\text{Bernoulli}(p)$, entonces la suma de $n$ observaciones sigue una distribución binomial $B(n, p)$. Aplicando el TCL:\n",
    "\n",
    "$$ \\frac{X - np}{\\sqrt{np(1 - p)}} \\approx N(0,1), \\quad \\text{para } n \\text{ grande} $$\n",
    "\n",
    "### **Ejemplo 2: Cálculo de reclamaciones de seguros**\n",
    "Una compañía de seguros tiene 25,000 clientes y cada cliente genera reclamaciones anuales con media de 320 y desviación estándar de 540. Aplicando el TCL, podemos estimar la probabilidad de que el total de reclamaciones exceda un umbral dado.\n",
    "\n",
    "### **Ejemplo 3: Estimación de distancia a una estrella**\n",
    "Un astrónomo quiere medir la distancia a una estrella y toma varias mediciones afectadas por ruido atmosférico. Si cada medición es una variable aleatoria con media $d$ y desviación estándar 2, se puede usar el TCL para estimar la precisión de la media muestral.\n",
    "\n",
    "### **Justificación de $n \\geq 30$**\n",
    "Se considera que para muchas distribuciones de población, el TCL proporciona una buena aproximación cuando $n \\geq 30$. Sin embargo, si la distribución original es altamente asimétrica, puede requerirse un tamaño de muestra mayor.\n",
    "\n",
    "## **7. Distribución Aproximada de la Media Muestral**\n",
    "Dado que la media muestral sigue aproximadamente una normal para muestras grandes:\n",
    "\n",
    "$$ \\bar{X} \\sim N \\left( \\mu, \\frac{\\sigma^2}{n} \\right) $$\n",
    "\n",
    "Se pueden construir intervalos de confianza y realizar pruebas de hipótesis basadas en esta aproximación.\n",
    "\n",
    "## **8. Varianza Muestral**\n",
    "La varianza muestral se define como:\n",
    "\n",
    "$$ S^2 = \\frac{1}{n - 1} \\sum_{i=1}^{n} (X_i - \\bar{X})^2 $$\n",
    "\n",
    "Es un estimador insesgado de la varianza poblacional $\\sigma^2$:\n",
    "\n",
    "$$ E[S^2] = \\sigma^2 $$\n",
    "\n",
    "Para una población normal, la varianza muestral sigue una distribución chi-cuadrado:\n",
    "\n",
    "$$ \\frac{(n-1)S^2}{\\sigma^2} \\sim \\chi^2_{n-1} $$\n",
    "\n",
    "## **9. Distribuciones Muestrales de una Población Normal**\n",
    "Si la población es normal, entonces:\n",
    "\n",
    "- La media muestral $\\bar{X}$ sigue una distribución normal:\n",
    "\n",
    "  $$ \\bar{X} \\sim N(\\mu, \\sigma^2/n) $$\n",
    "\n",
    "- La varianza muestral $S^2$ sigue una distribución chi-cuadrado.\n",
    "\n",
    "Además, $\\bar{X}$ y $S^2$ son independientes, lo que es una propiedad clave en inferencia estadística.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## **Referencias**\n",
    "- Ross, S. M. (2017). *Introduction to Probability and Statistics for Engineers and Scientists*. Academic Press.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
